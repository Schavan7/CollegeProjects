runif(10, 3, 6)
runnorm(10)
rnorm(10)
?seq
seq()
seq(3,5)
paste(1:3)
class(paste(1:3))
paste("xyz", 1:10)
rep(c(3,4,5), 5)
x= 1:20
x
which(x==10)
x[10]
myobject=1:10
myobject=1:10;myobject
x= sum(myobject)
x= sum(myobject);x
y= paste("R is great", c(4,7,45),"and I love it");y
x= rep(1:3, length=31);x
x[7]
myfirstfn= function(x){x=x};myfirstfn(10)
myfirstfn(10)
myfirstfn= function(x){x+x};myfirstfn(10)
for(i in 1:15){print(i)};
for(z in 1:15){print(z)}
?airmiles
head(airmiles)
tail(airmiles)
tail(airmiles)
summary(mtcars)
plot(mtcars)
hist(airmiles)
head(mtcars)
sum(mycars$wt)
sum(mtcars$wt)
mtcars(2,6)
mtcars[2,6]
mtcars[c(2,5,6),6]
plot(airmiles)
hist(airlmiles)
hist(airmiles)
number= scan()
numbers = scan()
numbers = scan()
View(myfirstfn)
View(myfirstfn)
function(x){x+x}
numbers= scan()
plot(lynx)
plot(lynx, main="Lynx Trappings", col="red",
col.main= 52, cex.main=1.5)
?rivers
x= 1:141
y = rivers
plot(x,y, col= "green", pch =20, main="Lengths of Major N. American rivers",
col.main="red", xlab ="", ylab="Lengths in miles")
plot(x,y, col= "green", pch =13, main="Lengths of Major N. American rivers",
col.main="red", xlab ="", ylab="Lengths in miles")
plot(x,y, col= "green", pch =11, main="Lengths of Major N. American rivers",
col.main="red", xlab ="", ylab="Lengths in miles")
plot(x,y, col= "green", pch =20, main="Lengths of Major N. American rivers",
col.main="red", xlab ="", ylab="Lengths in miles")
install.packages("ggplot2")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
?diamonds
head(diamonds)
attach(diamonds)
depthsmall = sample(depth,5000);
x = 10.5
x = 10.5
x
class(x)
mtcars
mtcars[1, 2]
mtcars[1, ]
mtcars[, 2]
mtcars$disp
mtcars[c(3,24),]
d = c(1, 2,3,4)
e = c("red", "white","red",NA)
f = c(TRUE,TRUE,TRUE, FALSE)
mydata = data.frame(d,e,f)
mydata
names(mydata)= c("ID","Color","passed")
mydata
mydata$Color
set.seed(10)
set.seed(50)
schtyp = sample(1:25, 20, replace = TRUE)
schtyp
schtyp
schtyp = sample(1:25, 20, replace = FALSE)
schtyp
schtyp
schtyp
schtyp.f = factor(schtyp, labels = c("private", "public"))
str(mtcars)
summary(mtcars)
mtcars$mpg
mtcars
mtcars$mpg[8]
mtcars[8]
mtcars[8,]
mtcars["Merc 240D", ]
mtcars[which.max(mtcars$mpg),]
set.seed(50)
attach(mtcars)
mtcars
mtcars[c(3,24), ]
source('~/Desktop/R/Online learning/test.R')
source('~/Desktop/R/Online learning/test.R')
source('~/Desktop/R/Online learning/test.R')
setwd("~/Desktop/ITM FALL 2017/Data Analsis_527/Project")
library(tidyverse)
library(reshape2)
library(Hmisc)
library(psych)
library(car)
library(alr3)
library("acepack", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
detach("package:alr3", unload=TRUE)
library("assertthat", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("alr3", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("caTools", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("cluster", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("corrplot", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("dbplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("DBI", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("ddalpha", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("highr", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("hexbin", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("irlba", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("lazyeval", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("lava", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("NbClust", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("party", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("partykit", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("pbkrtest", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("parallel", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("plotly", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("plogr", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("tools", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("tseries", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
housing = read.csv("housing.csv", header = TRUE)
summary(housing)
str(housing)
#plot(housing)
# NA's need to be addressed
# Split the factor valriable(ocean_proximity column) to binary values to make it compatible with other variables.
# Converted the total_bedrooms and total_rooms into a mean_number_bedrooms and
# mean_number_rooms columns for more accurate predictions
par(mfrow=c(1,1))
# gg plot to see
ggplot(data = melt(housing), mapping = aes(x = value)) +
geom_histogram(bins = 30) + facet_wrap(~variable, scales = 'free_x')
#STEP 2 - CLEANING THE DATA
# 1. Insert missing values.
# The only column with missing values is "total_bedrooms", So imputing the median data
# instead of mean  for NA's since median is less influenced by outliers.
housing$total_bedrooms[is.na(housing$total_bedrooms)] = median(housing$total_bedrooms , na.rm = TRUE)
#Cross verification:
str(housing)
summary(housing)
# 2. Convert total_rooms & total_bedrooms to mean of both the columns to scale the data.
housing$mean_bedrooms = housing$total_bedrooms/housing$households
housing$mean_rooms = housing$total_rooms/housing$households
str(housing)
drops = c('total_bedrooms', 'total_rooms')
housing = housing[ , !(names(housing) %in% drops)]
head(housing)
# 3. Converting the categorical variable into factors.
categories = unique(housing$ocean_proximity)
categories
housing$ocean_proximity <- as.factor(revalue(housing$ocean_proximity, c("<1H OCEAN"="1", "INLAND"="2", "ISLAND"="3", "NEAR BAY"="4", "NEAR OCEAN"="5")))
housing$ocean_proximity
# 4.Scaling the numeric variable.
# we scale all the variables except the median_house_value and ocean_proximity as
# median house value will be used to predict the outcome and ocean_proximity is a factor variable.
drops = c('ocean_proximity','median_house_value')
housing_num =  housing[ , !(names(housing) %in% drops)]
head(housing_num)
scaled_housing_num = scale(housing_num)
head(scaled_housing_num)
#5. Merge the altered numerical and categorical dataframes
cleaned_housing = cbind(scaled_housing_num, median_house_value =housing$median_house_value, ocean_proximity =housing$ocean_proximity)
head(cleaned_housing)
summary(cleaned_housing)
#pairs(cleaned_housing)
#plot(cleaned_housing)
set.seed(1000)
ind = sample(2, nrow(cleaned_housing), replace = TRUE, prob=c(0.7, 0.3))
train = cleaned_housing[ind == 1, ]
train = data.frame(train)
train = data.frame(train)
test = cleaned_housing[ind == 2, ]
test = data.frame(test)
head(train)
head(test)
nrow(train) + nrow(test) == nrow(cleaned_housing)
head(cleaned_housing)
d
cleaned_housing = data.frame(cleaned_housing)
fullModel = lm(median_house_value ~ latitude +longitude+ housing_median_age+ population + households+ median_income + mean_rooms + mean_bedrooms + ocean_proximity , data=train)
summary(fullModel)
fullModel
coef(fullModel)
plot(fullModel)
summary(fullModel)
ReducedModel1 =lm(median_house_value ~ latitude +longitude+ housing_median_age+ population + households+ median_income + mean_bedrooms + ocean_proximity , data=train)
summary(ReducedModel1)
ReducedModel2 =lm(median_house_value ~ latitude +longitude+ housing_median_age+ population + households+ median_income + mean_bedrooms, data=train)
summary(ReducedModel2)
cor(ReducedModel2)
cor(ReducedModel2)
ReducedModel2 =lm(median_house_value ~ latitude +longitude+ housing_median_age+ population + households+ median_income + mean_bedrooms, data=train)
summary(ReducedModel2)
cor(ReducedModel2)
cor(ReducedModel2)
library("colorspace", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("compiler", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("crayon", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
vif(ReducedModel2)
cor(ReducedModel2)
cor(data.frame(ReducedModel2))
cor(data.matrix(ReducedModel2))
cor.plot(ReducedModel2)
cor.plot(ReducedModel2)
cor(ReducedModel2)
library(psych)
library(Hmisc)
cor(cleaned_housing)
cor.plot(cleaned_housing)
vif(ReducedModel2)
ReducedModel3 =lm(median_house_value ~ latitude +longitude + housing_median_age + households+ median_income + mean_bedrooms, data=train)
summary(ReducedModel3) # All variables are very significant
ReducedModel3 =lm(median_house_value ~ latitude +longitude + housing_median_age + households+ median_income + mean_bedrooms, data=train)
summary(ReducedModel3) # All variables are very significant
ReducedModel4 = lm(median_house_value ~ latitude +longitude+ housing_median_age+ population + median_income + mean_bedrooms, data=train)
summary(ReducedModel4)
ReducedModel6 =lm(median_house_value ~  housing_median_age + households+ median_income + mean_bedrooms + (latitude * longitude) , data=train)
summary(ReducedModel6)
ReducedModel7 =lm(median_house_value ~ latitude +longitude + households + median_income + mean_bedrooms, data=train)
summary(ReducedModel7)
summary(ReducedModel3)
anova(ReducedModel1, ReducedModel2,ReducedModel3,ReducedModel4,ReducedModel5,ReducedModel6)
ReducedModel5 =lm(median_house_value ~ housing_median_age + households + median_income + mean_bedrooms, data=train)
summary(ReducedModel5)
ReducedModel6 =lm(median_house_value ~  housing_median_age + households+ median_income + mean_bedrooms + (latitude * longitude) , data=train)
summary(ReducedModel6)
ReducedModel7 =lm(median_house_value ~ latitude +longitude + households + median_income + mean_bedrooms, data=train)
summary(ReducedModel7)
summary(ReducedModel3)
anova(ReducedModel1, ReducedModel2,ReducedModel3,ReducedModel4,ReducedModel5,ReducedModel6)
anova(ReducedModel1, ReducedModel2,ReducedModel3,ReducedModel4,ReducedModel5,ReducedModel6)
FinalModel = ReducedModel3
prediction <- predict(FinalModel, test)
head(prediction)
head(test$median_house_value)
plot(test[,"median_house_value"], prediction,xlab = "actual", ylab = "predicted", main = "median_house_value")
plot(test[,"median_house_value"], prediction,xlab = "actual", ylab = "predicted", main = "median_house_value")
plot(test[,"median_house_value"], prediction,xlab = "actual", ylab = "predicted", main = "median_house_value")
abline(0,1, col="red")
plot(test[,"median_house_value"], prediction,xlab = "actual", ylab = "predicted", main = "median_house_value")
abline(0,1, col="red")
plot(test[,"median_house_value"], prediction,xlab = "actual",ylab = "predicted",main = "median_house_value")
par(mar = rep(2, 4))
plot(test[,"median_house_value"], prediction,xlab = "actual",ylab = "predicted",main = "median_house_value")
library("rpart.plot", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
plot(test[,"median_house_value"], prediction,xlab = "actual",ylab = "predicted",main = "median_house_value")
abline(0,1, col="red")
train$pred.price = predict(FinalModel, newdata = train)
test$pred.price = predict(FinalModel,  newdata = test)
summary(FinalModelv3)
train.corr = round(cor(train$pred.price, train$median_house_value), 2)
train.RSME = round(sqrt(mean((train$pred.price - train$median_house_value) ^ 2)))
train.MAE = round(mean(abs(train$pred.price - train$median_house_value)))
c(train.corr^2,train.RSME,train.MAE )
test.corr = round(cor(test$pred.price, test$median_house_value), 2)
test.RSME = round(sqrt(mean((test$pred.price - test$median_house_value) ^ 2)))
test.MAE = round(mean(abs(test$pred.price - test$median_house_value)))
c(test.corr^2,test.RSME,test.MAE )
train$pred.price = predict(FinalModel, train)
test$pred.price = predict(FinalModel,  test)
summary(FinalModel)
train.corr = round(cor(train$pred.price, train$median_house_value), 2)
train.RSME = round(sqrt(mean((train$pred.price - train$median_house_value) ^ 2)))
train.MAE = round(mean(abs(train$pred.price - train$median_house_value)))
c(train.corr^2,train.RSME,train.MAE )
test.corr = round(cor(test$pred.price, test$median_house_value), 2)
test.RSME = round(sqrt(mean((test$pred.price - test$median_house_value) ^ 2)))
test.MAE = round(mean(abs(test$pred.price - test$median_house_value)))
c(test.corr^2,test.RSME,test.MAE )
train$pred.price = predict(FinalModel, newdata= subset(train))
test$pred.price = predict(FinalModel,  newdata= subset(test))
summary(FinalModel)
train.corr = round(cor(train$pred.price, train$median_house_value), 2)
train.RSME = round(sqrt(mean((train$pred.price - train$median_house_value) ^ 2)))
train.MAE = round(mean(abs(train$pred.price - train$median_house_value)))
c(train.corr^2,train.RSME,train.MAE )
test.corr = round(cor(test$pred.price, test$median_house_value), 2)
test.RSME = round(sqrt(mean((test$pred.price - test$median_house_value) ^ 2)))
test.MAE = round(mean(abs(test$pred.price - test$median_house_value)))
c(test.corr^2,test.RSME,test.MAE )
ggplot(data = melt(housing), mapping = aes(x = value)) +
geom_histogram(bins = 30) + facet_wrap(~variable, scales = 'free_x')
library('boot')
?cv.glm
k_fold_cv_error = cv.glm(train , FinalModel, K=5)
k_fold_cv_error$delta
k_fold_cv_error$delta
glm_house = glm(median_house_value ~ latitude +longitude + housing_median_age + households+ median_income + mean_bedrooms, data=train)
k_fold_cv_error = cv.glm(train , glm_house, K=5)
k_fold_cv_error$delta
glm_cv_rmse = sqrt(k_fold_cv_error$delta)[1]
glm_cv_rmse
c(train.corr^2,train.RSME,train.MAE )
names(glm_house)
glm_house$coefficients
library(boot)
library(tidyverse)
housing = read.csv("housing.csv", header = TRUE)
summary(housing)
housing$ocean_proximity <- as.factor(revalue(housing$ocean_proximity, c("<1H OCEAN"="1", "INLAND"="2", "ISLAND"="3", "NEAR BAY"="4", "NEAR OCEAN"="5")))
housing$ocean_proximity
library(plyr)
library(dplyr)
housing$ocean_proximity <- as.factor(revalue(housing$ocean_proximity, c("<1H OCEAN"="1", "INLAND"="2", "ISLAND"="3", "NEAR BAY"="4", "NEAR OCEAN"="5")))
housing$ocean_proximity
categories = unique(housing$ocean_proximity)
categories
housing$ocean_proximity <- as.factor(revalue(housing$ocean_proximity, c("<1H OCEAN"="1", "INLAND"="2", "ISLAND"="3", "NEAR BAY"="4", "NEAR OCEAN"="5")))
categories
categories = unique(housing$ocean_proximity)
categories
housing$ocean_proximity <- as.factor(revalue(housing$ocean_proximity, c("<1H OCEAN"="1", "INLAND"="2", "ISLAND"="3", "NEAR BAY"="4", "NEAR OCEAN"="5")))
library(tidyverse)
library(reshape2)
library(Hmisc)
library(psych)
library(car)
library(alr3)
library(boot)
library(plyr)
library(dplyr)
# STEP 1: Importing the data
housing = read.csv("housing.csv", header = TRUE)
summary(housing)
str(housing)
#plot(housing)
# 207 NA's need to be addressed
# Split the factor valriable(ocean_proximity column) to binary values to make it compatible with other variables.
# Converted the total_bedrooms and total_rooms into a mean_number_bedrooms and
# mean_number_rooms columns for more accurate predictions
par(mfrow=c(1,1))
par(mar = rep(2, 4))
# ggplot to get a visual graph
ggplot(data = melt(housing), mapping = aes(x = value)) +
geom_histogram(bins = 30) + facet_wrap(~variable, scales = 'free_x')
# Predicting the graph, we can see that:
#1. There are some old age homes included in the data, as there is a hike in at the right most corner.
#2. The median house value also has a blip at the corner,may be the houses are in the bay area, hence they are expensive
#3. We need to scale the data, as there are outliers in all areas.
#STEP 2 - CLEANING THE DATA
# 1. Insert missing values.
# The only column with missing values is "total_bedrooms", So imputing the median data
# instead of mean  for NA's since median is less influenced by outliers.
housing$total_bedrooms[is.na(housing$total_bedrooms)] = median(housing$total_bedrooms , na.rm = TRUE)
#Cross verification:
str(housing)
summary(housing)
# 2. Convert total_rooms & total_bedrooms to mean of both the columns to scale the data.
housing$mean_bedrooms = housing$total_bedrooms/housing$households
housing$mean_rooms = housing$total_rooms/housing$households
str(housing)
drops = c('total_bedrooms', 'total_rooms')
housing = housing[ , !(names(housing) %in% drops)]
head(housing)
categories = unique(housing$ocean_proximity)
categories
directions <- c("North", "East", "South", "South")
housing$ocean_proximity <- c("<1H OCEAN", "INLAND" ,"ISLAND", "NEAR BAY", "NEAR OCEAN")
housing$ocean_proximity <- factor(housing$ocean_proximity)
housing$ocean_proximity
as.numeric(housing$ocean_proximity)
drops = c('ocean_proximity','median_house_value')
housing_num =  housing[ , !(names(housing) %in% drops)]
head(housing_num)
scaled_housing_num = scale(housing_num)
head(scaled_housing_num)
cleaned_housing = data.frame(cleaned_housing)
fullModel = lm(median_house_value ~ latitude +longitude+ housing_median_age+ population + households+ median_income + mean_rooms + mean_bedrooms + ocean_proximity , data=train)
summary(fullModel)
cor(cleaned_housing)
cor.plot(cleaned_housing)
names(train)
cleaned_housing = data.frame(cleaned_housing)
fullModel = lm(median_house_value ~ latitude +longitude+ housing_median_age+ population + households+ median_income + mean_rooms + mean_bedrooms + ocean_proximity , data=train)
plot(fullModel)
anova(ReducedModel1, ReducedModel2,ReducedModel3,ReducedModel4,ReducedModel5,ReducedModel6, ReducedModel7)
FinalModel
glm_house = glm(median_house_value ~ latitude +longitude + housing_median_age + households+ median_income + mean_bedrooms, data=train)
k_fold_cv_error = cv.glm(train , glm_house, K=5)
k_fold_cv_error$delta
glm_cv_rmse = sqrt(k_fold_cv_error$delta)[1]
glm_cv_rmse
names(glm_house)
glm_house$coefficients
?cv.glm
glm_house = glm(median_house_value ~ latitude +longitude + housing_median_age + households+ median_income + mean_bedrooms, data=train)
k_fold_cv_error = cv.glm(train , glm_house, K=5)
k_fold_cv_error$delta
glm_cv_rmse = sqrt(k_fold_cv_error$delta)[1]
glm_cv_rmse
names(glm_house)
glm_house$coefficients
FinalModel
glm_house = glm(median_house_value ~ latitude +longitude + housing_median_age + households+ median_income + mean_bedrooms, data=train)
k_fold_cv_error = cv.glm(train , glm_house, K=5)
k_fold_cv_error$delta
glm_cv_rmse = sqrt(k_fold_cv_error$delta)[1]
glm_cv_rmse
glm_house$coefficients
